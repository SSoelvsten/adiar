% ---------------------------------------------------------------------------- %
% INTRODUCTION
% ---------------------------------------------------------------------------- %
\section{Introduction} \label{sec:intro}

% ---------------------------------------------------------------------------- %
% PRELIMINARIES
% ---------------------------------------------------------------------------- %
\section{Preliminaries} \label{sec:preliminaries}

\subsection{The I/O Model}

\subsection{Ordered Boolean Decision Diagrams}

\begin{theorem}[\cite{Arge96}] \label{thm:reduce_io_lower_bound}

  Reduction of an OBBD $G$ with minimal pair, level, depth first or breadth
  first blocking requires $\Omega(\sort(N))$ I/Os in the worst case.
\end{theorem}

\begin{theorem}[\cite{Arge96}] \label{thm:apply_io_worst_case}

  The Dynamic Programming \Apply\ algorithm on two OBDDs of size $N_1, N_2$
  followed up by a \Reduce\ operation requires $O(N_1 \cdot N_2)$ I/Os in the
  worst case.
\end{theorem}


% ---------------------------------------------------------------------------- %
% THE ALGORITHM IN THEORY
% ---------------------------------------------------------------------------- %
\newpage
\section{Cache-oblivious OBBD algorithms} \label{sec:theory}

For completeness we provide both the \Reduce\ and \Apply\ algorithms of
\cite{Arge96}. We expand on these algorithms with a set of other algorithms for
the manipulation of OBBD.

The underlying idea of all the algorithms given below is to exploit that OBBD's
are directed acyclic graphs. If all nodes of an OBBD is sorted first by their
label and secondly by their unique identifier, then that constitutes a
topological sorting. As long as the dependency of computation only is one-way in
the OBBD, then a recursive algorithm can instead be handled by scanning through
all nodes in topological order and ``forward'' information to its children or
parent. This \emph{Time-Forward Processing} is done by use of one more priority
queues that are carefully synchronised with the scanning of the nodes \todocite.

These queues are aligned with the scan through all nodes by sorting all its
entries by the same ordering as the nodes. At the time of forwarding the
information, the receiving node is most likely not in memory. Since a lookup of
the receiving node would result in a full I/O used, then all nodes store both
the label and unique identifier of their children, as shown in
Code~\ref{lst:struct}.
\begin{lstfloat}
  \centering

  \begin{blstlisting}[language=sml, numbers=none]
  Struct Node {
    index : int;
    label : int;
    low   : { index: int?, label: int };
    high  : { index: int?, label: int };
  }
  \end{blstlisting}

  \caption{The information stored in each node of the OBBD}
  \label{lst:struct}
\end{lstfloat}

Since the label for the children is stored within the parent, then there is no
need to explicitly store the $0$- and $1$-sinks as nodes in the graph. Further
notice, that the Node contains no direct pointers to its children, but instead
only an index of where to find it an array. This is due to the fact that the
\Reduce\ algorithm described below outputs the nodes bottom-up and hence is able
to provide the index of the prior outputted children. That means, that an OBBD
as outputted by \Reduce\ can be traversed with the \Evaluate\ function in
Code~\ref{lst:eval}. For $n$ variables this traversal clearly takes $O(n)$ time
and $O(n)$ I/Os.
\begin{lstfloat}
  \centering

  \begin{blstlisting}[language=pseudocode, numbers=none]
  Evaluate(x : bool[], G : OBBD):
    v = G.V[G.V.length - 1] // The root is outputted last

    while True:
      if x[node.label]:
        if v.high.label$\in \set{0, 1}$: return v.high.label
        v = G.V[v.high.index]
      else:
        if v.low.label$\in \set{0, 1}$:  return v.low.label
        v = G.V[v.low.index]
  \end{blstlisting}

  \caption{The \Evaluate\ algorithm to traverse a reduced OBBD $G$ according to an
    assignment $x$}
  \label{lst:eval}
\end{lstfloat}

Except \Reduce, all algorithms given below assume that the input OBBD is reduced
and in reverse topological order, as outputted by the \Reduce\ algorithm. On the
other hand, the \Reduce\ algorithm expects the to-be-reduced list of nodes are
in topological order. Due to this, all sorting steps of the input nodes can
be omitted for the sake of optimisation. \cite{Arge96}

\subsection{Reduce} \label{sec:theory_reduce}
To create an I/O efficient \Reduce\ algorithm we make use of the following total
ordering in all three data structures: Given a node $v$ of the OBBD, sort it by
\lstinline{$v$.label} and break any ties at the same level by secondarily
sorting it by its identity \lstinline{$v$.uid}. This ordering is such that the
deepest nodes come first. Sink nodes come before any internal node.

This sorting is used in the following three data structures, where $a \in
\set{\textit{low}, \textit{high}}$.

\begin{itemize}
\item The list $L_1$ of all nodes $v \in V$ sorted with respect to $v$.

  This is to be used as the work-list of processing the nodes for the reduction.

\item The list $L_2$ of 3-tuples $(s,t,a)$ sorted with respect to $t$.

  This list is supposed to contain the node $s$ to which the result of its child
  $t$ has to be sent. Since every $s \in V$ is dependent on its two children
  $s.\mathit{low}$ and $s.\mathit{high}$, then both $(s, s.\mathit{low},
  \mathit{low})$ and $(s, s.\mathit{high}, \mathit{high})$ have to be included
  in $L_2$.

\item The priority queue $Q$ of 3-tuples $(s,t',a)$ sorted with respect to $s$.

  This priority queue is used to forward the result $t'$ of processing nodes $t
  \in L_1$ to nodes in $L_1$ dependent on $t'$.
\end{itemize}

The algorithm works by synchronous scanning through $L_1, L_2$ and extracting
from $Q$ the result of dependent information. By the ordering chosen, when
scanning an element $v \in L_1$ the next tuples of $L_2$ with $t = v$ contain
the $s$ dependent on the result $v'$ of the computation on $v$. Similarly, when
processing an element $s \in L_1$ the immediate next two elements of $Q$ will be
the tuples of with the result of processing its two children.

$L_1$ of length $N$ and $L_2$ of size $2 \cdot N$ can be populated in a single
scan of the input OBBD and sorted in $O(sort(N))$ I/O's. For each element of
$L_2$ a single element will be added to $Q$, which will result in $4 \cdot N$
insertions and deletions from $Q$, which also happens in worst-case $O(sort(N))$
I/O's when using an I/O efficient priority queue. On each layer all nodes are
sorted twice, which when all layers are combined results in another $O(sort(N))$
number of I/O's. Hence, the algorithm runs within the optimal $O(sort(N))$
bound. \cite{Arge96}

\subsection{Apply}


\subsection{Pipelining}


% ---------------------------------------------------------------------------- %
% THE ALGORITHM IN PRACTICE
% ---------------------------------------------------------------------------- %
\section{A Cache-oblivious OBBD implementation} \label{sec:implementation}


% ---------------------------------------------------------------------------- %
% CONCLUSION
% ---------------------------------------------------------------------------- %
\section{Conclusion} \label{sec:conclusion}


% ---------------------------------------------------------------------------- %
% References
% ---------------------------------------------------------------------------- %
\printbibliography

% ---------------------------------------------------------------------------- %
% Appendix
% ---------------------------------------------------------------------------- %
% \newpage \appendix
% \section{Appendix} \label{app:A}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "arxiv"
%%% End:
