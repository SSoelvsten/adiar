% ---------------------------------------------------------------------------- %
% INTRODUCTION
% ---------------------------------------------------------------------------- %
\section{Introduction} \label{sec:intro}

% ---------------------------------------------------------------------------- %
% PRELIMINARIES
% ---------------------------------------------------------------------------- %
\section{Preliminaries} \label{sec:preliminaries}

\subsection{The I/O Model}

\subsection{Ordered Boolean Decision Diagrams}

\begin{theorem}[\cite{Arge96}] \label{thm:reduce_io_lower_bound}

  Reduction of an OBBD $G$ with minimal pair, level, depth first or breadth
  first blocking requires $\Omega(\sort(N))$ I/Os in the worst case.
\end{theorem}

\begin{theorem}[\cite{Arge96}] \label{thm:apply_io_worst_case}

  The Dynamic Programming \Apply\ algorithm on two OBDDs of size $N_1, N_2$
  followed up by a \Reduce\ operation requires $O(N_1 \cdot N_2)$ I/Os in the
  worst case.
\end{theorem}


% ---------------------------------------------------------------------------- %
% THE ALGORITHM IN THEORY
% ---------------------------------------------------------------------------- %
\newpage
\section{Cache-oblivious OBBD algorithms} \label{sec:theory}

For completeness we provide both the \Reduce\ and \Apply\ algorithms of
\cite{Arge96}. We expand on these algorithms with a set of other algorithms for
the manipulation of OBBD.

The underlying idea of all the algorithms given below is to exploit that OBBD's
are directed acyclic graphs. If all nodes of an OBBD is sorted first by their
label and secondly by their unique identifier, then that constitutes a
topological sorting. As long as the dependency of computation only is one-way in
the OBBD, then a recursive algorithm can instead be handled by scanning through
all nodes in topological order and ``forward'' information to its children or
parent. This \emph{Time-Forward Processing} is done by use of one more priority
queues that are carefully synchronised with the scanning of the nodes \todocite.

These queues are aligned with the scan through by sorting all its entries by the
same ordering as the nodes. At the time of forwarding the information, the
receiving node is most likely not in memory. Hence, a lookup of the receiving
node would result in a full I/O used, which is not desired. To mitigate this,
all nodes store both the label and unique identifier of their children, as shown
in Code~\ref{lst:struct}.
\begin{lstfloat}
  \centering

  \begin{blstlisting}[language=pseudo, numbers=none]
  Type NodeArc = Sink of { value: bool }
               | Link of { index: int, label: int }

  Struct Node {
    index : int;
    label : int;
    low   : NodeArc;
    high  : NodeArc;
  }
  \end{blstlisting}

  \caption{The information stored in each node of the OBBD}
  \label{lst:struct}
\end{lstfloat}

Since the label for the children is stored within the parent, then there is no
need to explicitly store the $0$- and $1$-sinks as nodes in the graph. Further
notice, that the Node contains no direct pointers to its children, but instead
only an index of where to find it an array. This is due to the fact that the
\Reduce\ algorithm described below outputs the nodes bottom-up and hence is able
to provide the index of the prior outputted children. That means, that an OBBD
as outputted by \Reduce\ can be traversed with the \Evaluate\ function in
Code~\ref{lst:eval}, which for $n$ variables this takes $O(n)$ time and $O(n)$
I/Os.
\begin{lstfloat}
  \centering

  \begin{blstlisting}
  Evaluate(x : bool[], G : OBDD):
    v := G.V[G.V.length - 1] // The root is outputted last by Reduce

    while True:
      if x[node.label]:
        case v.high of Sink{ value }        => return value
                     | Link{ index, label } => v := G.V[index]
      else:
        case v.low of Sink{ value }        => return value
                    | Link{ index, label } => v := G.V[index]
  \end{blstlisting}

  \caption{The \Evaluate\ algorithm to traverse a reduced OBBD $G$ according to an
    assignment $x$}
  \label{lst:eval}
\end{lstfloat}

Except \Reduce, all algorithms given below assume that the input OBBD is reduced
and in reverse topological order, as outputted by the \Reduce\ algorithm. On the
other hand, the \Reduce\ algorithm expects the to-be-reduced list of nodes are
in topological order. Due to this, all sorting steps of the input nodes can
be omitted for the sake of optimisation. \cite{Arge96}

\subsection{Reduce} \label{sec:theory_reduce}
The \Reduce\ algorithm makes use of the following three data structures:

\begin{itemize}
\item The list \ReduceLwork\ of all nodes $v \in V$ sorted with respect to $v$.

  This is to be used as the work-list of processing the nodes for the reduction.

\item The list \ReduceLdep\ of 3-tuples
  \lstinline{(s: Node, t: NodeArc.Link, b: bool)}
  sorted with respect to the label and index of \lstinline{t}.

 This list is supposed to contain the node \lstinline{s} to which the result of
 its child \lstinline{t} has to be sent.

\item The priority queue \ReduceQdep\ of 3-tuples
  \lstinline{(s: Node, t': NodeArc.Link, b: bool)} sorted with
  respect to \lstinline{s} and secondly by \lstinline{b}.

  This priority queue is used to forward the result \lstinline{t'} of processing
  nodes \lstinline{t} $\in \ReduceLwork$ to nodes in $\ReduceLwork$ dependent on
  the result \lstinline{t'}.
\end{itemize}
These datastructures can be initialised as depicted in
Code~\ref{lst:reduce_init}. \ReduceLwork\ can be populated in topological
order in $O(\sort(N))$ I/Os. \ReduceLdep\ can also be populated with all
dependencies to non-sink children and sorted $O(\sort(N))$ I/Os. For simplicity
of the presentation of the \Reduce\ algorithm later we populate \ReduceQdep\
with all results of computation to the implicitly-stored sink nodes.%
\footnote{In actuality you would in the \Reduce\ algorithm below rather check
  whether the current node has an arc to a sink to minimise the number of
  elements placed in and retrieved from \ReduceQdep.}

\begin{lstfloat}[ht!]
  \centering

  \begin{blstlisting}
  $\ReduceLwork$ := G.V : Node[]
  sort nodes in $\ReduceLwork$

  $\ReduceLdep$ := [] : (Node, NodeArc, bool)[]
  $\ReduceQdep$ := $\emptyset$ : PriorityQueue<Node,NodeArc,bool>

  for $v \in \ReduceLwork$:
      low_dependency := (v, v.low, low)
      high_dependency := (v, v.high, high)

      case v.low of Sink{_}   => $\ReduceQdep$.insert(low_dependency)
                  | Link{_,_} => $\ReduceLdep$.append(low_dependency)

      case v.high of Sink{_}   => $\ReduceQdep$.insert(high_dependency)
                   | Link{_,_} => $\ReduceLdep$.append(high_dependency)

  sort (s,t,a) in $\ReduceLdep$ by t
  \end{blstlisting}

  \caption{Initialisation of datastructures for the \Reduce}
  \label{lst:reduce_init}
\end{lstfloat}

The \Reduce\ algorithm applies the reduction rules of \textcite{Bryant86} on all
nodes of each layer using the \lstinline{ReduceLayer} subroutine depicted in
Code~\ref{lst:reduce_bryant}. The output is are three lists
\lstinline{O}$_{\mathit{out}}$, \lstinline{O}$_{\mathit{red:}1}$,
\lstinline{O}$_{\mathit{red:}2}$ of tuples \lstinline{(w,w',i)} of mapping
between the original nodes \lstinline{w} of the input and nodes \lstinline{w'}
to-be or already outputted. The \lstinline{i} value contains the index of the
original node \lstinline{w} for reasons that will become apparent later.

\begin{lstfloat}[ht!]
  \centering

  \begin{blstlisting}
  reduce_layer(data: (v: Node, low: NodeArc, high: NodeArc)[]):
      sort (v, low, high) in data by low first and high second
      O$_{\mathit{out}}$, O$_{\mathit{red:}1}$, O$_{\mathit{red:}2}$ = []

      for i := 0 to data.length - 1:
          (w, w_low, w_high) = data[i]

          // Reduction rule 1:
          if w_low = w_high:
              O$_{\mathit{red:}1}$.append((w,w_low,w.index))
          else:
              w' = {
                index: NIL,
                label: w.label,
                low: w_low,
                high: w_high
              }
              O$_{\mathit{out}}$.append(w,w',w.index)

              w$_{\mathit{arc}}'$ = {
                index: NIL,
                label: w.label,
              }

              // Reduction rule 2:
              while i < data.length:
                  (o, o_low, o_high) = data[i]
                  if w_low = o_low $\land$ w_high = o_high:
                      O$_{\mathit{red:}2}$.append((o,w$_{\mathit{arc}}'$,w.index))
                      i++

      return (O$_{\mathit{out}}$, O$_{\mathit{red:}1}$, O$_{\mathit{red:}2}$)
  \end{blstlisting}

  \caption{Subroutine applying reduction rules of \cite{Bryant86} within \Reduce}
  \label{lst:reduce_bryant}
\end{lstfloat}

We are now ready to present the \Reduce\ algorithm. The algorithm takes as
argument all the three datastructures described above and assumes they are all
are initialised. We choose to do this, to make explicit the ability of the later
algorithms to populate all three datastructures for free. The \Reduce\ algorithm
is presented in Code~\ref{lst:reduce_algorithm}.

It proceeds by computing and outputting the reduced OBBD bottom-up and layer for
layer. This is done by a single scan through the work list \ReduceLwork, where
the nodes of each layer are merged with the result of the recursion to then
apply the reduction rules of \cite{Bryant86} on the whole layer. The recursive
dependencies are handled through \ReduceQdep\ which is synchronised with the
scan of \ReduceLwork\ while using \ReduceLdep\ to fill \ReduceQdep\ with the
next dependencies outputted.


\begin{lstfloat}
  \centering

  \begin{blstlisting}
    Reduce($\ReduceLwork$: Node[],
           $\ReduceLdep$: (Node,NodeArc,bool)[],
           $\ReduceQdep$: PriorityQueue<Node,NodeArc,bool>):
      // Index of next output in stream
      iO = 0

      // Index into *@\color{cGray} $\ReduceLwork$@*
      iW := $\ReduceLwork$.length - 1
      v := $\ReduceLwork$[iW]

      // Index into *@\color{cGray} $\ReduceLdep$@*
      iD = $\ReduceLdep$.length - 1

      // Process bottom-up each layer except for the root-layer
      for j := n-1 downto 2:
          $L_{j}$ := []

          // Merge nodes of layer j with result of prior computations
          while v.label = j:
              (_, t1, _) := $\ReduceQdep$.get_next()
              (_, t2, _) := $\ReduceQdep$.get_next()

              $L_{j}$.append((v,t1,t2))
              v := $\ReduceLwork$[--iW]

          // Apply reduction rules
          ($L_{j,\mathit{out}}$, $L_{j,\mathit{red:}1}$, $L_{j,\mathit{red:}2}$) = reduce_layer($L_{j}$)

          // Output to-be outputted nodes and distribute output index
          sort (w,w',i) in $L_{j,\mathit{out}}$ and $L_{j,\mathit{red:}2}$ by i

          iM = 0
          for (w,w',i) in $L_{j,\mathit{out}}$:
              w'.index := iO++
              output w'

              while iM < $L_{j,\mathit{red:}2}$.length $\land$ $L_{j,\mathit{red:}2}$[iM] is (_,_,i):
                  $L_{j,\mathit{red:}2}$[iM++][1].index := w'.index

          // Forward processing information to layers j-1 .. 1
          $L_{j,\mathit{forward}}$ := $L_{j,\mathit{out}}$ ++ $L_{j,\mathit{red:}1}$ ++ $L_{j,\mathit{red:}2}$
          sort (w,w',i) in $L_{j,\mathit{forward}}$ by w.index

          (s, t, b) := $\ReduceLdep$[iD]
          for (w,w') in $L_{j,\mathit{out}}$, $L_{j,\mathit{red:}2}$:
              while t = w:
                  $\ReduceQdep$.insert((s,w',b))
                  (s, t, b) := L2[--iD]

      // Process the root
      (_, t_low,  _) := $\ReduceQdep$.get_next()
      (_, t_high, _) := $\ReduceQdep$.get_next()
      output { label: v.label, index: iO, low: t_low, high: t_high }
  \end{blstlisting}

  \caption{The \Reduce\ algorithm}
  \label{lst:reduce_algorithm}
\end{lstfloat}

\clearpage
As mentioned, \ReduceLwork\ and \ReduceLdep\ can be initialised in $O(sort(N))$
I/O's. For each element of \ReduceLdep\ a single element will be added to
\ReduceQdep, which will result in a total $4 N$ insertions and deletions from
\ReduceQdep, which also happens in worst-case $O(sort(N))$ I/O's when using an
I/O efficient priority queue. On each layer all nodes are sorted thrice, which
when all layers are combined results in another $O(sort(N))$ total number of I/O's.
Hence, the algorithm runs within the optimal $O(sort(N))$ I/O bound and in $O(N
\log N)$ time. \cite{Arge96} By similar obsevations we can also conclude, that
the algorithm has an $O(N \log N)$ time complexity.

\subsection{Substitute} \label{sec:theory_substitute}
Before we present the \Apply\ algorithm we present the simpler top-down
algorithm \Substitute, which given an OBDD $G$ and an assignment vector $A$ of
tuples $(x_i, \mathit{value})$ outputs a reduced OBD $G_{| x_i = v ,\ \forall
  (x_i,v) \in A}$ as shown in Code~\ref{lst:substitute}.

\begin{itemize}
\item The priority queue \Q\ of 3-tuples
  \lstinline{(s: Node, t: NodeArc.Link, b: bool)} sorted with
  respect to \lstinline{t} only.

  This the tuples $(s,t,b)$-tuples in the priority queue are used to forward
  recursion requests from $s$ to non-sink children $t$.
\end{itemize}

The algorithm essentially traverses the OBDD recursively, either keeping the
node and recursing along both outgoing arcs or skipping the node and only
recursing on the arc according to the assignment. The recursion is controlled
using \Q.

Since this only traverses the OBDD top-down, the nodes traversed do not know the
index of their children before they are outputted later. Hence, these nodes will
not contain an actual index to their children, but instead only a unique
identifier of \lstinline{int}-tuples. Luckily, these references
can be fixed as part of the bottom-up traversal of the final \Reduce.
Furthermore, due to the top-down traversal of the OBDD, the \ReduceLwork\,
\ReduceLdep\ and \Q\ of \Reduce\ can be initialised during the traversal.

\begin{lstfloat}
  \centering

  \begin{blstlisting}
  Substitute(G : OBDD, A : (int, bool)[]):
      sort (l,v) in A *@by@* l
      Q, $\ReduceQdep$ = $\emptyset$ : PriorityQueue<Node,NodeArc,bool>
      $\ReduceLwork, \ReduceLdep$ := [] : Node[] | (Node,NodeArc,bool)[]

      iA := 0
      (a_label, a_value) := A[iA]

      // Process the root and create initial recursion requests
      v = G.V[G.V.length - 1]
      if a_label = v.label:
          if a_value:
              if is_sink(v.high): return sink-only OBDD v.high.value
              Q.insert ((NIL, v.high, True))
          else:
              if is_sink(v.low): return sink-only OBDD v.low.value
              Q.insert((NIL, v.low, False))

          (a_label, a_value) := A[++iA]
      else:
          $\ReduceLwork$.append(v)
          high_request := (v, v.high, True)
          low_request := Q.insert(v, v.low, False)

          if !is_sink(v.high): Q.insert(high_request)
          else: $\ReduceQdep$.insert(high_request)

          if !is_sink(v.low):  Q.insert(low_request)
          else: $\ReduceQdep$.insert(low_request)

      // Process all to-be-visited nodes in topological order
      while !Q.empty():
          (s,t,a) := Q.get_next()
          v := G.V[t.index]

          // Skip to-be-substituted variables that we didn't see
          while a_label < v.label: (a_label, a_value) := A[++iA]

          // Forward the desired information
          if a_label <> v.label:
              $\ReduceLwork$.append(v)
              Q.insert((v, v.low, False), (v, v.high, True))

              // v is outputted: dependencies (if any) to v
              // can be locked in place
              if s <> NIL:
                  while True:
                      $\ReduceLdep$.append((s,t,a))
                      if Q.peek()[1] = v: (s,t,a) := Q.get_next()
                      else: break
          else:
              rec_child := if a_value then v.high else v.low
              recurse := !is_sink(rec_child)
              request := (s, rec_child, a_value)

              if recurse: Q.insert(request)
              else if s = NIL: return sink-only OBDD rec_child.value
              else: $\ReduceQdep$.insert(request)

      return Reduce($\ReduceLwork, \ReduceLdep, \ReduceQdep$)
  \end{blstlisting}

  \caption{The \Substitute\ algorithm}
  \label{lst:substitute}
\end{lstfloat}

By the ordering of tuples in \Q, then nodes are visited in topological order,
which means each block of \GV\ is only fetched at most once. This means that at
most $O(N/B)$ I/O's are used as part of the look up of vertices in \GV. At most
$2N$ requests are placed and retrieved from \Q\ which will only require
$O(sort(N))$ I/Os. For $N' \leq N$ the number of nodes put into the resulting
list of nodes, \ReduceLwork, then the use of \Reduce\ will only result in
$O(sort(N'))$ I/O's. In total the \Substitute\ algorithm performs the full
substitution and reduction in $O(sort(N))$ I/Os.

\clearpage
\subsection{Apply}


\subsection{Relational Product}


% ---------------------------------------------------------------------------- %
% THE ALGORITHM IN PRACTICE
% ---------------------------------------------------------------------------- %
\section{A Cache-oblivious OBBD implementation} \label{sec:implementation}


% ---------------------------------------------------------------------------- %
% CONCLUSION
% ---------------------------------------------------------------------------- %
\section{Conclusion} \label{sec:conclusion}


% ---------------------------------------------------------------------------- %
% References
% ---------------------------------------------------------------------------- %
\printbibliography

% ---------------------------------------------------------------------------- %
% Appendix
% ---------------------------------------------------------------------------- %
% \newpage \appendix
% \section{Appendix} \label{app:A}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "arxiv"
%%% End:
