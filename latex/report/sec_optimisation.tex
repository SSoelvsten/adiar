% ---------------------------------------------------------------------------- %
% OPTIMISATIONS DESCRIPTION
% ---------------------------------------------------------------------------- %
\section{Optimisations} \label{sec:optimisations}
The primary intent of the presentation of the algorithms above was to convey the
idea of Time Forward Processing applied on the topological ordering og OBDDs.
This closely followed the algorithm as in \cite{Arge96}. We will now point out
multiple avenues to improve the constants in the I/O and time complexity at the
cost of the code complexity.

\subsection{Reduce}
Since \Reduce\ is used at the end of all other algorithms, any small ounce of
speed one can squeeze out of this function will have noticable implications on
the speed of the others. In the presentation of the algorithm above, we already
improved the algorithm by merging the input OBDD with the supporting data
structure of the transposed graph, but we also propose the optimisations below.

\subsubsection{Separate sink-dependency list}
The main bottleneck of the \Reduce\ algorithm is the use of the priority queue
\ReduceQdep, why we would want to minimise the number of elements within. In the
algorithm we assumed \ReduceQdep\ is prepopulated with the sink dependencies and
were able to do do so in all prior algorithms.

We notice, that the sink-dependencies always are placed in \ReduceQdep\ in
topological order, which means all \lstinline{Edge}s are are sorted with respect
to their \lstinline{source}. Hence, one can instead prepopulate a list
$L_{\mathit{Red:}Sinks}$, from which the sink dependencies are retrieved rather
than from \ReduceQdep.

\todo[inline]{Experimentally settle the ratio of sinks relative to $N$ to
  discern the possible speedup.}

\subsubsection{Early application of the first reduction rule}
At the time of extracting the dependencies \lstinline{e_low} and
\lstinline{e_high} of a node \lstinline{v} from \ReduceQdep, one already has all
the information needed to potentially apply the first reduction rule. Hence, one
may immediately populate the list of rule 1 reduced nodes,
$L_{j:\mathit{red}:1}$ instead of extracting it later in
\lstinline{reduce_layer}. This will save one from having to scan those elements
multiple times.

\todo[inline]{Experimentally settle a value the number of rule-1 reduced nodes.}

\subsubsection{Implicit merge of the reduction lists}
One should notice, that one does not need to concatenate and sort the three
lists $L_{j,\mathit{out}}$, $L_{j,\mathit{red:}1}$, $L_{j,\mathit{red:}2}$ to
create $L_{j:F}$, since one may instead merely sort the three lists and
implicitly take \lstinline{(w,w',_)} from $L_{j:F}$ by picking the next eleement
from either of the three lists, similarly to the classic \lstinline{merge}
subprocedure of merge sort.


\subsection{Representation of nodes for faster sorting}
Inspired by \cite{Dijk16} we propose to represent the \lstinline{NodeArc} type
of Code~\ref{lst:data_node} as a single 64-bit integer as shown in
Figure~\ref{fig:data}. A \lstinline{NodeArc.Sink} of value $v \in \{0,1\}$ is
represented by a $1$-flag on the most significant bit, $v$ on the least
significant bit, and all other bits set to $0$.\footnote{Notice, that we as such
  leave room for sinks taking on non-boolean values of up to $2^{63}$ bits.} A
\lstinline{NodeArc.Link} has a $0$-flag on the most significant bit, the next
$k$-bits dedicated to the \lstinline{label}, and finally the $63-k$ least
significant bits contain the \lstinline{value}. A reasonable value for $k$ is
$21$, since this supports an OBDD of up to $2^k = 2^{21} \approx 2 \cdot 10^7$
variables and of size up to $2^{63-k} = 2^{42} \approx 4.45 \cdot 10^{12}$
nodes.

\todo[inline]{Intermediate results may be larger than $10^{12}$ nodes. This can
  stay within this setup by resetting the ``index'' for each layer. This
  preserves the ordering.}

\begin{figure}[ht!]
  \centering

  \begin{subfigure}{0.49\linewidth}
    \centering \input{../tikz/data_sink.tex}
    \caption{\lstinline{NodeArc.Sink\{value: v\}} where \lstinline{v} $\in
      \{0,1\}$}
    \label{fig:data_sink}
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering \input{../tikz/data_link.tex}
    \caption{\lstinline{NodeArc.Link\{label, index\}}}
    \label{fig:data_link}
  \end{subfigure}

  \caption{Visual representation of data layout. The least significant bit is
    right-most.}
  \label{fig:data}
\end{figure}

A \lstinline{Node} can then be represented by $3$ $64$-bit numbers: Two $64$-bit
integers for each child and another $64$ bits for the \lstinline{label} and
\lstinline{index} of the node itself with the same layout as for
\lstinline{NodeArc.Link}.

One should notice, that the sorting in the previous section with this layout is
a trivial sorting on $64$-bit numbers. In the case of the bottom-up sweep
algorithm, the sorting is in descending order, while the top-down sweep
algorithms use a sorting in ascending order. Tuples $(t_1,t_2)$ in \Apply\ and
\Equal\ are then $64$-bit numbers $\min(t_1,t_2)$ when \lstinline{data} is not
present. Since \lstinline{data} is only present for pairs of nodes with the same
\lstinline{label}, then the number to sort by simply becomes $\max(t_1,t_2)$.
Whether it is faster to repeatedly compute $\min$ and $\max$ during sorting, or
precompute it at insertion time at the cost of increasing the size of each
element by another $64$-bits, is worth experimental investigation.

The representation of variables \lstinline{Node} and \lstinline{NodeArc} as a
single $64$-bit integers does result in having to do bit shifts and bit masking
to access the values. Such instructions though are computationally very cheap,
and are quickly offset by the smaller memory size and especially the much
cheaper comparisons during sorting. This reduction to numbers might even open up
investigating the use of $O(N)$ time and $O(\sort(N))$ I/O non-comparative sorting
algorithm, such as the ones in \todocite.

\subsection{Equality checking}
One should notice, that all algorithms as they have been described above are
\emph{stable} in the sense, that the ordering of nodes within each layer is
preserved. That means, one can check whether an OBDD $G$ is unchanged after one
or more manipulations by comparing it with the result $G'$ in a single linear
scan, which only takes $O(N/B)$ I/Os.

\todo[inline]{This is still too slow! In model checking, one wants to compute
  the transitive closure by repeatedly applying \RelProd\ and checking whether
  the output is unchanged. This check is in conventional OBDD libraries done in
  $O(1)$ time with a mere pointer comparison.

  \begin{center}
    We should be able to do the same with taint tracking?
  \end{center}
}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
