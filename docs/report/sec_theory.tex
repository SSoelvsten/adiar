% ---------------------------------------------------------------------------- %
% THE BASIC ALGORITHM DESCRIPTION
% ---------------------------------------------------------------------------- %
\newpage
\section{OBDD manipulations using Time-Forward Processing} \label{sec:theory}

For completeness we provide both the \Reduce\ and \Apply\ algorithms of
\cite{Arge96}. We expand on these algorithms with a set of other algorithms for
the manipulation of OBDD.

The underlying idea of all the algorithms given below is to exploit that OBDD's
are directed acyclic graphs. If all nodes of an OBDD is sorted first by their
label and secondly by their unique identifier, then that constitutes a
topological sorting. As long as the dependency of computation only is one-way in
the OBDD, then a recursive algorithm can instead be handled by a single sweep
through all nodes in topological order and ``forward'' information to its
children or parent. This \emph{Time-Forward Processing} is done by use of one
more priority queues that are carefully synchronised with the scanning of the
nodes \todocite.

These queues are aligned with the scan through the list of nodes by sorting all
their entries by the same topological ordering. At the time of forwarding the
information, the receiving node is most likely not in memory. Hence, a lookup of
the receiving node would result in a full I/O used, which is not desired. To
mitigate this, all nodes store both the label and unique identifier of their
children. Since the label for the children is stored within the parent, then
there is no need to explicitly store the $0$- and $1$-sinks as nodes in the
graph. The data stored for each node then is as depicted in
Code~\ref{lst:data_node}.
\begin{lstfloat}[ht!]
  \centering

  \input{../listing/data_node.tex}

  \caption{The information stored in each node of the OBDD}
  \label{lst:data_node}
\end{lstfloat}

\noindent The reader should notice, that the Nodes contains no direct pointers
to its children, but instead only an index of where to find it in the list of
all nodes. This is a direct consequence of the iterative design of all the
algorithms below.

All manipulating algorithms are followed by a \Reduce, which outputs the nodes
bottom-up. That means, that an OBDD as outputted by \Reduce\ can be traversed
with the \Evaluate\ function in Code~\ref{lst:evaluate}, which easily can be
seen for $n$ variables will take $O(n)$ time and $O(\min(n, N/B))$ I/Os.
\begin{lstfloat}[ht!]
  \centering

  \input{../listing/evaluate_algorithm.tex}

  \caption{The \Evaluate\ algorithm to traverse a reduced OBDD $G$ according to an
    assignment $x$}
  \label{lst:evaluate}
\end{lstfloat}

Except \Reduce, all algorithms given below assume that the input OBDD is reduced
and in reverse topological order, as outputted by the \Reduce\ algorithm. On the
other hand, the \Reduce\ algorithm expects the to-be-reduced list of nodes are
in topological order - as outputted by the other algorithms. Due to this, all
initial sorting of the input nodes can be omitted, and we will choose to do so
in our description of them. \cite{Arge96}

Arge~\cite{Arge96} suggests to further exploit the above by rather representing
the OBDD by its edges, rather than its nodes. Since \lstinline{NodeArc} contains
all the identifying information of a \lstinline{Node}, then this leads to a
representation as a list of \lstinline{Edges} as in Code~\ref{lst:data_edge}.
The \Evaluate\ algorithm above still works by finding the out-going arcs of node
$i$ at indices $2i$ and $2i+1$. In fact, all node-based algorithms below may as
well be done on the edge-based representation.

\begin{lstfloat}[ht!]
  \centering

  \input{../listing/data_edge.tex}

  \caption{The information stored in each edge of the edge-based representation}
  \label{lst:data_edge}
\end{lstfloat}

One should note, that a single \lstinline{Node} when represented as two
\lstinline{Edges} now takes up at least $4/3$ as much space as before, since the
\lstinline{source} has to be stored for both edges. In fact nothing is gained
when the edges are in topological order. On the other hand, reverse topological
order is obtained merely by sorting the list of edges by \lstinline{target}.
This culminates in our observation, that one of the supporting data structures
of the \Reduce\ algorithm as described by Arge~\cite{Arge96} is exactly the
edge-based representation sorted by \lstinline{target}. Hence, we will opt to
merge this data structure and the input OBDD. This both simplifies the
algorithm, but much more importantly it also reduces the memory footprint by at
least a third.

\subsection{Reduce} \label{sec:theory__reduce}
The \Reduce\ algorithm makes use of the following two data structures:

\begin{itemize}
\item The input list \ReduceLforward\ of \lstinline{Edges} sorted in increasing
  order with respect to \lstinline{target}. This provides a work-order to
  processing the nodes in reverse topological order for the reduction by
  traversing the list backwards. Furthermore, this also directly provides which
  nodes \lstinline{s} depend on the computation result \lstinline{t'} of a node
  \lstinline{t}.

\item The priority queue \ReduceQdep\ of \lstinline{Edges} sorted with
  respect to \lstinline{source} and secondly by \lstinline{is_high}.

  This priority queue is used to forward the result \lstinline{t'} of processing
  nodes \lstinline{t} as per \ReduceLforward\ to any nodes \lstinline{s} with an
  edge to \lstinline{t}.
\end{itemize}
We assume, that \ReduceLforward\ does not contain any edges with
\lstinline{target} a sink, but rather that \ReduceQdep\ has already been
populated with all sink dependencies. One can scan through \ReduceLforward\ and
move all sink edges to \ReduceQdep\ within the $O(\sort(N))$ I/Os bound, but we
want to highlight the ability of all the algorithms in the later sections are
able to create \ReduceLforward\ in the desired order and populate \ReduceQdep\
with all the sink dependencies with no extra work required.

The \Reduce\ algorithm applies the reduction rules of \textcite[Definition
5]{Bryant86} on all nodes of each layer using the \lstinline{reduce_layer}
subroutine depicted in Code~\ref{lst:reduce_bryant}. The output are the three
lists \lstinline{O}$_{\mathit{out}}$, \lstinline{O}$_{\mathit{red:}1}$,
\lstinline{O}$_{\mathit{red:}2}$ of tuples \lstinline{(w,w')}. The list
\lstinline{O}$_{\mathit{out}}$ contitutes the list of nodes to be outputted,
\lstinline{O}$_{\mathit{red:}1}$ the nodes reduced due to the first reduction
rule, and finally the list \lstinline{O}$_{\mathit{red:}2}$ of nodes reduced to
the second rule. The tuple creates a mapping between the original nodes
\lstinline{w} of the input and the to-be-outputted nodes \lstinline{w'}.

\begin{lstfloat}[ht!]
  \centering

  \input{../listing/reduce_layer.tex}

  \caption{Subroutine applying reduction rules of \cite{Bryant86} within \Reduce}
  \label{lst:reduce_bryant}
\end{lstfloat}

We are now ready to present the \Reduce\ algorithm as it is depicted in
Code~\ref{lst:reduce_algorithm}. It proceeds by computing and outputting the
reduced OBDD bottom-up and layer for layer according to the reverse topological
order. Upon having processed layer $j$ according to Code~\ref{lst:reduce_bryant}
above, then the reduced layer is immediately outputted and all nodes
\lstinline{s} that depend on the outputted node \lstinline{t'} in layer $j$ is
forwarded \lstinline{t'} through \ReduceQdep\ as per the edge \lstinline{(s,t)}
in \ReduceLforward. Since \ReduceQdep\ already contains all sink-dependencies
and due to the bottom-up processing of the layers then \ReduceQdep\ will always
contain all dependencies when one begins to process any layer.

A total of $2 N$ edges will be inserted into \ReduceQdep\ and then later again
extracted, while \ReduceLforward\ is scanned once at the end to forward
information. This totals a $O(\sort(4N) + N/B) = O(\sort(N))$ number of I/Os
spent. On each layer all nodes are sorted twice, which when all layers are
combined results in another $O(\sort(N))$ total number of I/Os. Hence, the
algorithm runs within the optimal $O(\sort(N))$ I/O bound \cite{Arge96}. By
similar observations we can also conclude, that the algorithm has an $O(N \log_2
N)$ time complexity.

\begin{lstfloat}
  \centering

  \input{../listing/reduce_algorithm.tex}

  \caption{The \Reduce\ algorithm}
  \label{lst:reduce_algorithm}
\end{lstfloat}

\clearpage
\subsection{Restrict} \label{sec:theory__restrict}
Before we present the \Apply\ algorithm we present the simpler top-down
algorithm \Restrict, which task as input

\begin{itemize}
\item The input list \lstinline{G} of \lstinline{Nodes} in reverse topological
  order, i.e. sorted in decreasing order to \lstinline{label} and then
  \lstinline{id}. The root is then at the very end, and the next node to be
  processed can be found by seeking backwards.

\item The input list \lstinline{A} of assignments \lstinline{(x$_i$, value)} of
  type \lstinline{int$\times$bool}, assumed to be sorted by the label
  \lstinline{x$_i$}.
\end{itemize}
from which the graph \lstinline{G}$_{| x_i = v_i ,\ \forall (x_i,v_i) \in A}$
will be computed and then reduced by a succeeding use of \Reduce. Internally
this uses the priority queue \RestrictQrec\ of \lstinline{Edges} sorted with
respect to \lstinline{target} only. These edges in the priority queue are used
to forward recursion requests from \lstinline{source} to non-sink children
\lstinline{target} along a $b$-arc.

The algorithm as depicted in Code~\ref{lst:restrict} essentially traverses the
OBDD recursively, either keeping the node and recursing along both outgoing arcs
or skipping the node and only recursing on the arc according to the assignment.
The recursion is controlled using \RestrictQrec. Since the traversal is
top-down, then the algorithm can without extra effort populate \ReduceLforward\
and \ReduceQdep\ of the later \Reduce\ in the desired order; the
\lstinline{source} of the edge for \ReduceLforward\ is provided from
\RestrictQrec\ at the time of processing its \lstinline{target}.

\begin{lstfloat}
  \centering

  \input{../listing/restrict_algorithm.tex}

  \caption{The \Restrict\ algorithm}
  \label{lst:restrict}
\end{lstfloat}

By the ordering of tuples in \RestrictQrec, nodes are visited in topological
order, which also is the blocking of the nodes on disk. This means every block
is fetched at most once and at most $O(N/B)$ I/Os are used as part of the look
up of vertices in \lstinline{G}. At most $2N$ requests are placed and retrieved
from \Q\ which will only require $O(sort(N))$ I/Os. let $N' \leq N$ be the
number of nodes outputted for the later \Reduce, which then also only uses
another $O(sort(N')) = O(sort(N))$ I/Os. In total the \Restrict\ algorithm
performs the full substitution and reduction in $O(sort(N))$ I/Os and $O(N \log
N)$ time.

\subsection{Apply} \label{sec:theory__apply}
The \Apply\ algorithm computes the to-be reduced combined OBDD given the input
\begin{itemize}
\item The input lists \lstinline{G}$_1$ and \lstinline{G}$_2$ of
  \lstinline{Nodes} to be combined, sorted in decreasing order by
  \lstinline{label} and then \lstinline{id}.

\item A binary operator \lstinline{op} to obtain the resulting sink of two sinks
  from \lstinline{G}$_1$ and \lstinline{G}$_2$.
\end{itemize}

Similar to \Restrict, the \Apply\ algorithm makes use of a priority queue to
forward the recursion to nodes visited later in topological order. In
\cite{Arge96} four priority queues were used to make the algorithm easier to
follow. We hope to make the algorithm still comprehensible while only using a
single queue. This will result in a constant improvement in the running time.
Since this queue has to be synchronised with the scan of both list of nodes at
the same time, then the sorting is a bit more complicated than in the prior
given algorithms. The data structure used is the priority queue \ApplyQrec\ of
4-tuples \lstinline{(s', (t$_1$,t$_2$), is_high, data)} where \lstinline{s'},
\lstinline{t$_1$}, and \lstinline{t$_2$} are of type \lstinline{NodeArc},
\lstinline{is_high} of \lstinline{bool} and \lstinline{data} of
\lstinline{Option(NodeArc)}.

\newpage
This queue forwards requests for recursion from processing the pair of nodes
$(s_1, s_2)$ output as \lstinline{s'} to $(t_1,t_2)$ through a $b$-arc. The
\lstinline{data} element is used when $t_1$ and $t_2$ have the same label such
that the first visited can be forwarded to to the second for processing. Hence,
the sorting of an element is dependant on whether \lstinline{data} is provided
in the tuple.

\begin{itemize}
\item If \lstinline{data} is \lstinline{None}, then it is sorted first with
  respect to $\min(t_1.\mathit{label},t_2.\mathit{label})$, secondly with respect
  to $\min(t_1.\mathit{index},t_2.\mathit{index})$. Sinks
  (\lstinline{NodeArc.Sink}) come after nodes\\(\lstinline{NodeArc.Ptr}).

\item If \lstinline{data} is \lstinline{Some(v)}, then it is still first
  sorted with respect to $\min(t_1.\mathit{label},t_2.\mathit{label})$, but
  secondly dually with respect to $\max(t_1.\mathit{index}, t_2.\mathit{index})$.
  For two requests to the same $(t_1,t_2)$ the one with \lstinline{data} comes
  first.
\end{itemize}

The reader should notice that in the general case of \lstinline{data} being
\lstinline{None}, then the sorting is a generalisation of the sorting of nodes
used up until this point.

To match the general sorting above the \lstinline{apply_step} function below in
Code~\ref{lst:apply_step} mutates variables $\mathit{iW}_1$ and $\mathit{iW}_2$
being indices in the respective input lists \lstinline{G$_1$} and
\lstinline{G$_2$} of vertices together with the corresponding vertices $v_1$ and
$v_2$.
\begin{lstfloat}
  \centering

  \input{../listing/apply_step.tex}

  \caption{Determining in which OBDD should be progressed matching the sorting}
  \label{lst:apply_step}
\end{lstfloat}

The \Apply\ algorithm constructs an OBDD that simulates both OBDDs $G_1$ and
$G_2$ at the same time. At a node representing a $(v_1,v_2)$ the label of the
output node is $\min(v_1.\mathit{label},v_2.\mathit{label})$. Hence, the initial
recursion requests placed into then created from the root pair of nodes from the
same notion resolved as in \lstinline{apply_root} in Code~\ref{lst:apply_root}.
\begin{lstfloat}[hb!]
  \centering

  \input{../listing/apply_root.tex}

  \caption{Resolving the root pair $(v_1, v_2)$.}
  \label{lst:apply_root}
\end{lstfloat}


In the case the two labels of $v_1$ and $v_2$ differ, then the recursion is only
dependent on the node with the smallest label. Otherwise, \lstinline{data} is
used to send the data of the first-seen node to the second for processing later,
such that both are in memory simultaneously. That is, for all cases but when
\lstinline{data} is not present yet both \lstinline{t$_1$} and \lstinline{t$_2$}
have the same label, then the node pair to recurse to or the sink to output can
be resolved by the function \lstinline{apply_node} as depicted in
Code~\ref{lst:apply_node}.
\begin{lstfloat}[ht!]
  \centering

  \input{../listing/apply_node.tex}

  \caption{Resolving the label and children of the $(v_1, v_2)$ pair.}
  \label{lst:apply_node}
\end{lstfloat}

Since sinks are stored in parents, then a sink-sink recursion requests is not
placed into \ApplyQrec\ in favour of resolving the resulting child immediately
and place it in \ReduceQdep. Putting everything above together, we can create
the \Apply\ algorithm as presented in Code~\ref{lst:apply_algorithm}.

\begin{lstfloat}[ht!]
  \centering

  \input{../listing/apply_algorithm}

  \caption{The \Apply\ algorithm}
  \label{lst:apply_algorithm}
\end{lstfloat}

Let $N_1$ and $N_2$ be the respective sizes of $G_1$ and $G_2$. By the nature of
how both lists are scanned, then only $O(N_1 + N_2)$ I/Os are spent on scanning
the nodes. There is at most $N_1 \cdot N_2$ many nodes being outputted,
resulting in at most $O(N_1 N_2 / B)$ I/Os spent on writing the output for the
later \Reduce\ that will take $O(\sort(N_1 N_2))$ I/Os. Each element creates up
to two requests for recursions, each of which may be reinserted to forward data
later into the queue. That means, an $O(N_1 N_2)$ number of elements are
inserted and retrieved from \ApplyQrec\ which requires $O(\sort(N_1 N_2))$ I/Os.
By the same account the algorithm also spends $O(N_1 N_2 \cdot \log_2 (N_1 N_2))$
time for computation. \cite{Arge96}

\clearpage
\subsection{Isomorphism} \label{sec:theory__equal}
Two reduced OBDDs represent the same boolean function if and only if they are
isomorphic \cite[Theorem 1]{Bryant86}. Hence, no two reduced OBDDs with
different number of nodes can be isomorphic. Using the same approach as for the
\Apply\ algorithm above and a single priority queue \IsomorphicQrec\, one can
traverse both graphs and check that they behave similarly.

Since nodes directly contain the label and index of their children, the
algorithm can be further optimised. Rather than testing for equality of the
label in the node pair $(v_1,v_2)$ itself, one instead checks both
$(v_1.\mathit{low}, v_2.\mathit{low})$ and $(v_1.\mathit{high},
v_2.\mathit{high})$ to be the same sink-value or pointer to nodes of the same
layer. This makes the algorithm able to terminate earlier when given two unequal
OBDDs. Since the algorithms terminates on the first violation, the space and
time usage reduces to $O(\sort(\min(N_1, N_2)))$ I/O and time complexity.

\subsection{Exists} \label{sec:theory__exists}

Following up on the design of \Restrict\ and \Apply\ above, one may think to
implement an \Exists\ algorithm by a single sweep down and then reduce in a single
sweep back up again. On the down sweep, in an unquantified layer one follows
both outgoing arcs of the current node. A node \lstinline{v} on a quantified
layer is skipped to instead connect \lstinline{v}'s parents with the \emph{or}
of it's two children \lstinline{v.low} and \lstinline{v.high}. As such, this
idea is sound, but one runs into the issue of the possible exponential increase
in the OBDD; at each quantified layer a single arc is the composition of two.
For $n'$ many variables to quantify, one will have to maintain request of up to
$2^{n'}$ nodes each. \todo[inline, caption={Algorithm: Exists in a single
  sweep?}]{ Can you bridge the exponential nature somehow into a separate
  counter or id to restrict yourself to a constant number of nodes? What if you
  initially keep the to-be quantified nodes? }

Instead we will process the resulting OBDD bottom-up while maintaining the
intermediate result of all the processed layers beneath the current. When a node
\lstinline{v} in a layer has to be quantified, then the disjunction of their
children is computed in a subprocedure similar to \Apply\ that goes back down
again in the intermediate result to compute the new nodes needed. For this, we
will make use of the following data structures.

\begin{itemize}
\item The input list \lstinline{G} of \lstinline{Nodes} sorted in reverse
  topological order, i.e. in decreasing order by \lstinline{label} and then by
  \lstinline{id}.

\item The input list \lstinline{V} of to-be quantified variable
  \lstinline{labels}, also sorted in reverse.

\item The list \ExistsLforward\ of non-sink \lstinline{Edges} in \lstinline{G}
  sorted in decreasing order by their target. Similar to \ReduceLforward\ this
  provides a work-order of nodes in reverse topological order and together with
  where information has to be forwarded.

\item The priority queue \ExistsQdep\ with \lstinline{Edges} sorted with respect
  to their \lstinline{source} and secondly by \lstinline{is_high}. This again is
  used similar to the priority queue \ReduceQdep.

\item The list \ExistsLres\ of nodes sorted in reverse topological order. This
  will contain the intermediate reduced partial result of layers beneath the
  currently processed.
\end{itemize}

The \Exists\ algorithm proceeds by processing nodes layer-by-layer. If the layer
is not to be quantified, then the layer merely needs to be reduced based on the
result of the layers below. The reduced nodes are then placed in \ExistsLres.
When a layer has to be quantified, then one of the following cases apply to a
node \lstinline{v} in the layer

\begin{enumerate}
\item A child of \lstinline{v} is a sink with its \lstinline{value} being
  \lstinline{True}. The disjunction of its children would be the same and this
  sink may be directly forwarded to any dependencies on \lstinline{v}.

\item Similarly, for a sink-child with its \lstinline{value} being
  \lstinline{False}, then one may merely forward the other child.

\item Otherwise, the or of \lstinline{v.low} and \lstinline{v.high} has
  to be processed. This would require new nodes in the layers below, which
  then have to be reprocessed.
\end{enumerate}

While traversing the layer and gathering the results of computation one can
identify which case of the above that applies. Since all nodes on the same layer
are independent, one may postpone processing the \emph{or} of their children
until one can do them all at once.

Reprocessing all layers below is then done with a modified version of \Apply\ on
the list \ExistsLres. The algorithm \lstinline{exists_or} differs from \Apply\
that it is optimised for the disjunction on a single OBDD, allows multiple
initial requests to be provided with a priority queue, and it is stable with
regards to the naming of nodes present before processing. The last part is
important, since the priority queue \ExistsQdep\ may contain forwarded results
from layers within \ExistsLres. For the same reason, \lstinline{exists_or} also
takes \ExistsLforward\ as a third argument, to determine whether a node is dead
or some node to-be processed later is dependant on it. For this to work, the
algorithm also needs to maintain \ExistsLforward\ for processing later layers by
replacing the node name of quantified nodes with the result of their
computation.

We omit the pseudocode of \lstinline{exists_or} while the pseudocode \Exists\
can be found in Code~\ref{lst:exists}. Let $n' \leq n$ be the number of layers
to be quantified, then $n'$ times will \lstinline{exists_or} be called to sweep
back down through \ExistsLres, each time spending $\sort(\abs{\ExistsLres})$
I/Os. The maximum size of \ExistsLres\ when having processed $j$ to-be
quantified layers is $N^j$, so the sum of total nodes processed by
\lstinline{exists_or} is $O ( (N (N^{n'} - 1)) / (N - 1) ) = O(N^{n'})$
resulting in a total of $O(\sort(N^{n'}))$ number of I/Os. Reducing
non-quantified layers only will take an $O(\sort(N))$ number of I/Os, and the
number of requests in \ExistsQdep is $2N$, which by itself also only will
contribute with another $O(\sort(N))$ number of I/Os. The total number of I/Os
then is $O(\sort(N^{n'})$. The same analysis also applies to time spent.

\begin{lstfloat}[ht!]
  \centering

  \input{../listing/exists.tex}

  \caption{The \Exists\ algorithm}
  \label{lst:exists}
\end{lstfloat}

\todo[inline, caption={Algorithm: Exists as a pipeline?}]{
  Could one do a multi-sweep only downwards? That is, first settle the topmost
  existential, then the second topmost existential and so on. This could be
  fully pipelined... }

\subsection{Relational Product} \label{sec:theory__relational_product}
\todo[inline, caption={Algorithm: Relational Product}]{
  We should be able to do the same as for \Exists?
}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% ispell-local-dictionary: "british"
%%% End:
